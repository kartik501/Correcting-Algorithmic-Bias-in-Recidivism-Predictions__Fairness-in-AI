# Fairness-in-AI---COMPAS-Recidivism
Implemented a Conditional Non-discrimination classifier and a Fairness-Aware classifier with Prejudice Remover Regularizer to reduce racial bias in recidivism predictions.

# Fairness in AI - COMPAS Recidivism

## Objective:

Fairness algorithms, a recent topic in machine learning, aims to avoid outcome decisions that are unfair to certain groups or individuals. In this project we implement two of such fairness algorithms, (insert link) and (insert link), in an attempt to reduce racial bias and improve fairness in recividism predictions for individuals.

## Dataset:
COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a popular commercial algorithm used by judges and parole officers for scoring criminal defendantâ€™s likelihood of reoffending (recidivism). The dataset used in this project contains variables used by the COMPAS algorithm in scoring defendants, along with their outcomes within 2 years of the decision, for over 10,000 criminal defendants in Broward County, Florida. 

## Accuracy Metrics:
The metric for evaluating fairness varies based on the context of the problem. However, in this project comparions between the algorithms were made on the basis on overall accuracy, calibration score ( difference between accuraies of each class) and Flase Positive Rate (FPR) of each class.

## Methodology:

## Paper 1:

## Paper 2:

## Results:
